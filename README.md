# mem_PPO
 - - -
## Introduction
- Implementations of On-shot memory + PPO(with GAE) with Pytorch
- Run in "CartPole-v0" environment.

## Algorithms
- PPO
- Learning to Remember Rare Events


# References
## Github
- https://github.com/reinforcement-learning-kr/Unity_ML_Agents
- https://github.com/seungeunrho/minimalRL
- https://github.com/RUSH-LAB/LSH_Memory

## Paper
- [PPO](https://arxiv.org/pdf/1707.06347)
- [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)
- [Learning to Remember Rare Events](https://arxiv.org/abs/1703.03129)
